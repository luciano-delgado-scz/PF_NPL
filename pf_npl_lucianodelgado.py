# -*- coding: utf-8 -*-
"""PF-NPL-LucianoDelgado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dLVrw0y22_ehDDhIZzyu1iW03R91lGFp

# Proyecto Final 🤖
Curso: NPL (Coder House)

**Alumno: Luciano Delgado**
"""

import pandas as pd

### Procesamiento de texto
import re
import inflect
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer

### Model Building & Feature Selection & Parameter Tuning ###
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, chi2

### Classification Algos ###
from sklearn.naive_bayes import MultinomialNB, GaussianNB
from sklearn.tree import DecisionTreeClassifier

### Evaluation & Visualization Modules ###
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn import metrics
import matplotlib.pyplot as plt

"""Descargo un dataset de mails clasificados como Spam/NoSpam, con las labels ya predefinidas (este proceso en general lo hace un humano uno a uno y sirve como input al modelo que uno quiera aplicar)"""

# Descargo de la sección "Archivos" dentro de este notebook
df = pd.read_csv(r'spam_or_not_spam.csv')
df

df.info()

df.dropna(inplace=True)

df['label'].value_counts()

duplicates_df = df[df.duplicated()]
duplicates_df.shape

df

df.drop_duplicates(inplace=True)
len(df)

"""# Procesamiento de texto"""

def remove_punctuation(text):
    ### Remove the punctuation marks ###
    text = re.sub(r"\W", " ", text) # replaces anything other than letters, digits, underscore character with a white space
    text = re.sub(r'\s+', " ", text) # removes extra white spaces

    ### Lowercase the text ###
    text = text.lower()
    return text

df['email'] = df['email'].apply(remove_punctuation)
df.head()

"""# Remuevo stopwords"""

import nltk
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

def remove_stopwords(text):
    words = text.split()
    words = [word for word in words if word not in stop_words]
    return ' '.join(words)

df['email'] = df['email'].apply(remove_stopwords)

df.head()

"""Reemplazo dígitos por su representación textual"""

p = inflect.engine()
def convert_digits(text):
    words = text.split()
    new_text = []

    for word in words:
        if word.isdigit():
            new_text.append(p.number_to_words(word))
        else:
            new_text.append(word)

    return ' '.join(new_text)

df['email'] = df['email'].apply(convert_digits)

df.head()

# Steeming ???
ps = PorterStemmer()

def stemming(text):
    words = text.split()
    words = [ps.stem(word) for word in words]
    return ' '.join(words)

df['email'] = df['email'].apply(stemming)
df.head(10)

"""Vertorización"""

vectorizer = TfidfVectorizer()
x_vector = vectorizer.fit_transform(df['email'])
y = df['label']

"""Dividir en set de Entregmiento y Test"""

x_train, x_test, y_train, y_test = train_test_split(x_vector, y, test_size=0.3)

### Tuning parameters using multiple k values for selecting best number of features
param_grid = {
    'selector__k': [5, 10, 15, 20, 25, 30, 35, 40]
}

# Define a function to create pipelines and perform grid search for each classifier
def grid_search_for_classifier(clf, param_grid, x_train, y_train):
    pipeline = Pipeline([
        ('selector', SelectKBest(chi2)),
        ('classifier', clf)
    ])

    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1')
    grid_search.fit(x_train, y_train)

    return grid_search

"""# Algoritmo de clasificación y medición de Accuracy

**1. Classification: NaiveBayesMultinomial**
"""

# Parameter Tuning & Training: Perform grid search for MultinomialNB
multinomial_nb = MultinomialNB()
grid_search_mnb = grid_search_for_classifier(multinomial_nb, param_grid, x_train, y_train)
best_mnb_model = grid_search_mnb.best_estimator_
# print(f"Best parameters for MultinomialNB: {grid_search_mnb.best_params_}")

# Predicting & Evaluating Accuracy: MultinomialNB
y_pred_mnb = best_mnb_model.predict(x_test)

mnb_accuracy = accuracy_score(y_test, y_pred_mnb)

print("MultinomialNB Accuracy Score: " + str(mnb_accuracy))
print("MultinomialNB Error Rate " + str(1-mnb_accuracy))

"""Matriz de confusión"""

cm = confusion_matrix(y_test, y_pred_mnb)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])
cm_display.plot()

plt.show()

"""- No Spam: El modelo predijo todos los no-span con presición

- Spam: Predijo la mayoría falsamente como "No Spam"

**2. NaiveBayes: Gaussian NB**
"""

# Parameter Tuning & Training: Perform grid search for GaussianNB (standard NaiveBayes)
# GaussianNB requires dense matrix
x_train_dense = x_train.toarray()
x_test_dense = x_test.toarray()
gaussian_nb = GaussianNB()
grid_search_gnb = grid_search_for_classifier(gaussian_nb, param_grid, x_train_dense, y_train)
best_gnb_model = grid_search_gnb.best_estimator_
# print(f"Best parameters for GaussianNB: {grid_search_gnb.best_params_}")

# Predicting & Evaluating accuracy: GaussianNB: NaiveBayes
y_pred_gnb = best_gnb_model.predict(x_test_dense)
gnb_accuracy = accuracy_score(y_test, y_pred_gnb)
print("GaussianNB Accuracy Score: " + str(gnb_accuracy))
print("GaussianNB Error Rate: " + str(1-gnb_accuracy))

cm = confusion_matrix(y_test,y_pred_gnb)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])
cm_display.plot()

plt.show()

"""- El modelo predijo todos los No Spam con precisión con algunos pocos predichos como Spam

- El modelo predijo la mayoría de los Spam correctamente con algunos falsamente predichos como No Spam

**3. J48 (Decision Tree Classifier)**
"""

# Parameter Tuning & Training: Perform grid search for J48 (DecisionTreeClassifier)
j48 = DecisionTreeClassifier()
grid_search_j48 = grid_search_for_classifier(j48, param_grid, x_train, y_train)
best_j48_model = grid_search_j48.best_estimator_
# print(f"Best parameters for J48: {grid_search_j48.best_params_}")

# Predicting & Evaluating: J48
y_pred_j48 = best_j48_model.predict(x_test)
j48_accuracy = accuracy_score(y_test, y_pred_j48)
print("J48 Accuracy Score:" + str(j48_accuracy))
print("J48 Error Rate:" + str(1-j48_accuracy))

cm = confusion_matrix(y_test,y_pred_j48)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])
cm_display.plot()

plt.show()

"""

J48 o Decision Tree predijo la mayoria de los No Spam con precisión así como también los Spam. Ambos presentando un alto grado de accuracy superior al 90%"""

